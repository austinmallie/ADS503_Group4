---
title: "ADS 503 Final Project"
author: "Austin Mallie, Kirsten Emily Drennen, Brendan Robinson"
date: "2025-06-11"
output: pdf_document
---

```{r}
library(readxl)
library(dplyr)
library(readr)
library(lubridate)
library(geosphere)
library(tidyr)
library(FNN)
library(tidyverse)
library(corrplot)
library(summarytools)
library(stringr)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(MASS)
library(shiny)
```


```{r}
# Load Bleach Data
bleaching_data <- read_xlsx("Global_Coral_Bleaching_Database.xlsx")
# Load SST data
sst_data <- read_csv("sst_annual_avg_by_location.csv")

```

```{r}
# Clean column names
colnames(bleaching_data) <- make.names(colnames(bleaching_data))

# Inspect structure
str(bleaching_data)
dim(bleaching_data)
head(bleaching_data)


dfSummary(bleaching_data)

# Latitude & Longitude (Distribution of site locations)

ggplot(bleaching_data, aes(x = LATITUDE)) +
  geom_histogram(bins = 50, fill = "lightblue", color = "black") +
  labs(title = "Histogram of LATITUDE", x = "Latitude", y = "Frequency")

ggplot(bleaching_data, aes(x = LONGITUDE)) +
  geom_histogram(bins = 50, fill = "lightgreen", color = "black") +
  labs(title = "Histogram of LONGITUDE", x = "Longitude", y = "Frequency")


# YEAR

ggplot(bleaching_data, aes(x = YEAR)) +
  geom_histogram(binwidth = 1, fill = "coral", color = "black") +
  labs(title = "Histogram of YEAR", x = "Year", y = "Number of Observations")


# PERCENT_BLEACHED and MORTALITY 

# Clean Percent Bleached first:
bleaching_data <- bleaching_data %>%
  mutate(PERCENT_BLEACHED_CLEAN = suppressWarnings(as.numeric(PERCENT_BLEACHED)))


ggplot(bleaching_data, aes(x = PERCENT_BLEACHED_CLEAN)) +
  geom_histogram(bins = 50, fill = "orange", color = "black", na.rm = TRUE) +
  labs(title = "Histogram of PERCENT_BLEACHED", x = "% Bleached", y = "Frequency")

# PERCENT_MORTALITY 
bleaching_data <- bleaching_data %>%
  mutate(PERCENT_MORTALITY_CLEAN = suppressWarnings(as.numeric(PERCENT_MORTALITY)))

ggplot(bleaching_data, aes(x = PERCENT_MORTALITY_CLEAN)) +
  geom_histogram(bins = 50, fill = "red", color = "black", na.rm = TRUE) +
  labs(title = "Histogram of PERCENT_MORTALITY", x = "% Mortality", y = "Frequency")


# COUNTRY

ggplot(bleaching_data, aes(x = reorder(COUNTRY, COUNTRY, function(x)-length(x)))) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Observations per Country", x = "Country", y = "Count") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))


# Heat MAP
years_to_plot <- c(1985, 2000, 2015)

ggplot(sst_data %>% filter(year %in% years_to_plot), 
       aes(x = lon, y = lat, fill = avg_sst)) +
  geom_tile() +
  facet_wrap(~ year) +
  coord_fixed() +
  scale_fill_viridis_c(option = "magma") +
  labs(title = "Global Sea Surface Temperature by Year", fill = "SST (°C)") +
  theme_minimal()


# SST ANUAL AVG DIST.
ggplot(sst_data, aes(x = avg_sst)) +
  geom_histogram(bins = 50, fill = "steelblue") +
  labs(title = "Distribution of Annual Average SST", x = "Sea Surface Temp (°C)", y = "Count") +
  theme_minimal()

```


```{r}
ggplot(bleaching_data, aes(x = PERCENT_BLEACHED_CLEAN, y = PERCENT_MORTALITY_CLEAN)) +
  geom_point(alpha = 0.3, color = "darkred") +
  labs(title = "Scatterplot: % Bleached vs % Mortality",
       x = "% Bleached", y = "% Mortality") +
  theme_minimal()

ggplot(bleaching_data, aes(x = YEAR, y = PERCENT_BLEACHED_CLEAN)) +
  geom_point(alpha = 0.3, color = "coral") +
  geom_smooth(method = "loess", color = "blue") +
  labs(title = "Scatterplot: % Bleached over Years",
       x = "Year", y = "% Bleached") +
  theme_minimal()

ggplot(bleaching_data, aes(x = YEAR, y = PERCENT_MORTALITY_CLEAN)) +
  geom_point(alpha = 0.3, color = "firebrick") +
  geom_smooth(method = "loess", color = "blue") +
  labs(title = "Scatterplot: % Mortality over Years",
       x = "Year", y = "% Mortality") +
  theme_minimal()

ggplot(bleaching_data, aes(x = LONGITUDE, y = LATITUDE)) +
  geom_point(alpha = 0.3, color = "steelblue") +
  labs(title = "Geographic Distribution of Coral Bleaching Observations",
       x = "Longitude", y = "Latitude") +
  theme_minimal()

```

In the next code block the bleach data set will be cleaned so that the column names and the values within them will be more helpful during the modeling process.

```{r}

# Clean percent columns (bleaching & mortality)
clean_percent <- function(x) {
  x <- as.character(x)
  
  if (is.na(x) || x == "N/A") return(NA_real_)
  
  x <- str_trim(x)
  x <- str_remove_all(x, "[^0-9\\-\\.]+")  # Keep digits, dash, decimal
  
  if (str_detect(x, "-")) {
    nums <- str_split(x, "-")[[1]]
    nums <- as.numeric(nums)
    return(mean(nums, na.rm = TRUE))
  }
  
  val <- suppressWarnings(as.numeric(x))
  return(val)
}

# Apply cleaning to bleaching and mortality columns
bleaching_data <- bleaching_data %>%
  mutate(
    PERCENT_BLEACHED_CLEAN = sapply(PERCENT_BLEACHED, clean_percent),
    PERCENT_MORTALITY_CLEAN = sapply(PERCENT_MORTALITY, clean_percent),
    MIN_PERCENT_BLEACHED_CLEAN = sapply(MIN_PERCENT_BLEACHED, clean_percent),
    MAX_PERCENT_BLEACHED_CLEAN = sapply(MAX_PERCENT_BLEACHED, clean_percent)
  )

```

Here the data sets will be merged on their lat and long values. Due to the differences in how the data sets handle their latitude and longitude values, grid rounding will be employed to help pair the sets together. The SST data is collected on a predefined spatial grid which often has values such as .25 degrees or 1 degree, whereas the bleaching set has precised lat and long values that do not align with the SST points. Therefore the data sets will need to be merged based on areas defined by areas that cover specific spans of Longitude and Latitude. This way geographic areas are better covered and get representation
```{r}
# Use geographic areas of waters for the bleaching set
bleaching_data <- bleaching_data %>%
  mutate(
    AREA = case_when(
      LATITUDE >= -30 & LATITUDE <= -10 & LONGITUDE >= 110 & LONGITUDE <= 160 ~ "Southwest Pacific",
    LATITUDE >= -10 & LATITUDE <= 10 & LONGITUDE >= 90 & LONGITUDE <= 180 ~ "Equatorial Pacific",
    LATITUDE >= 10 & LATITUDE <= 30 & LONGITUDE >= -80 & LONGITUDE <= -30 ~ "Caribbean",
    LATITUDE >= 10 & LATITUDE <= 30 & LONGITUDE >= 100 & LONGITUDE <= 140 ~ "South China Sea",
    LATITUDE >= -30 & LATITUDE <= 30 & LONGITUDE >= 20 & LONGITUDE <= 80 ~ "Indian Ocean",
    LATITUDE >= -40 & LATITUDE <= 40 & LONGITUDE >= -180 & LONGITUDE <= -80 ~ "Eastern Pacific",
    TRUE ~ "Other"
  ))

# Same with the SST set
sst_data <- sst_data %>%
  mutate(
    AREA = case_when(
   lat >= -30 & lat <= -10 & lon >= 110 & lon <= 160 ~ "Southwest Pacific",
    lat >= -10 & lat <= 10 & lon >= 90 & lon <= 180 ~ "Equatorial Pacific",
    lat >= 10 & lat <= 30 & lon >= -80 & lon <= -30 ~ "Caribbean",
    lat >= 10 & lat <= 30 & lon >= 100 & lon <= 140 ~ "South China Sea",
    lat >= -30 & lat <= 30 & lon >= 20 & lon <= 80 ~ "Indian Ocean",
    lat >= -40 & lat <= 40 & lon >= -180 & lon <= -80 ~ "Eastern Pacific",
    TRUE ~ "Other"
  ))

sst_area_summary <- sst_data %>%
  group_by(AREA, year) %>%
  summarise(avg_sst = median(avg_sst, na.rm = TRUE), .groups = "drop")


merged_data <- left_join(
  bleaching_data,
  sst_area_summary,
  by = c("AREA", "YEAR" = "year"))
  
# Quick check of the merged dataset
glimpse(merged_data)

```


```{r}

# Check for any missing data
colSums(is.na(merged_data))


```

Data preprocessing
```{r}
# The target of the study is not the mortality of the reefs but rather the bleaching of them. There are far too many values that are missing from this column so it will be dropped. Also columns that have no predictive value or are just metadata will be dropped as well. Min percent bleach, max percent bleach can also be dropped because they are strongly correlated with the percent bleached clean target variable
merged_data <- merged_data %>%
  dplyr::select(
    -RECORD_ID,
    -SURVEY_TYPE,
    -DATA_POINT_OF_CONTACT,
    -POC_E.MAIL_ADDRESS,
    -CITATION,
    -COMMENTS,
    -PERCENT_MORTALITY,
    -PERCENT_MORTALITY_CLEAN,
    -MIN_PERCENT_BLEACHED,
    -MAX_PERCENT_BLEACHED,
    -SOURCE,
    -CORAL_REGIONS,
    -SITE_NAME
  )



```


```{r}

# Here we will clean the depth column and make it ready for modeling while also creating bins for the ranges of values depth can take.
# Clean up DEPTH column 
merged_data <- merged_data %>%
  mutate(
    DEPTH_CLEAN = as.character(DEPTH),
    DEPTH_CLEAN = ifelse(
      DEPTH_CLEAN %in% c("N/A", "NA", "", " ", "unknown", "UNK", "null", "NULL"),
      NA, DEPTH_CLEAN
    ),
    DEPTH_CLEAN = str_remove_all(DEPTH_CLEAN, "[^0-9\\.\\-]+"),
    DEPTH_CLEAN = ifelse(
      str_detect(DEPTH_CLEAN, "-"),
      sapply(str_split(DEPTH_CLEAN, "-"), function(x) {
        nums <- suppressWarnings(as.numeric(x))
        if (all(is.na(nums))) {
          return(NA_real_)
        } else {
          return(mean(nums, na.rm = TRUE))
        }
      }),
      DEPTH_CLEAN
    ),
    DEPTH_CLEAN = as.numeric(DEPTH_CLEAN)
  )

# # Since Percent_Bleached_Clean is the target variable we can drop the empty rows because it injects artificial data within the target. We cannot accurately impute the SST values without introducing bias into the model so those values will be dropped as well
merged_data_clean <- merged_data %>%
  filter(!is.na(PERCENT_BLEACHED_CLEAN)) %>%
  filter(!is.na(avg_sst))

# Group based depth imputation based on lat, long and year
merged_data_clean <- merged_data_clean %>%
  group_by(AREA, YEAR) %>%
  mutate(
    DEPTH_CLEAN = ifelse(
      is.na(DEPTH_CLEAN),
      median(DEPTH_CLEAN, na.rm = TRUE),
      DEPTH_CLEAN
    )
  ) %>%
  ungroup()

# Fall back redundancy just in case some missing values are missing, so the median depth is used in place
global_median_depth <- median(merged_data_clean$DEPTH_CLEAN, na.rm = TRUE)

merged_data_clean <- merged_data_clean %>%
  mutate(
    DEPTH_CLEAN = ifelse(
      is.na(DEPTH_CLEAN),
      global_median_depth,
      DEPTH_CLEAN
    )
  )

# Bin Depth
merged_data_clean <- merged_data_clean %>%
  mutate(
    DEPTH_BIN = case_when(
      DEPTH_CLEAN <= 5 ~ "Very Shallow",
      DEPTH_CLEAN <= 10 ~ "Shallow",
      DEPTH_CLEAN <= 20 ~ "Mid",
      DEPTH_CLEAN <= 40 ~ "Deep",
      DEPTH_CLEAN > 40 ~ "Very Deep"
    )
  )

```


```{r}
# We can now drop the depth column because all of the necessary information from in is now stored in depth_clean and Depth_bin
merged_data_clean <- merged_data_clean %>% 
  dplyr::select(-DEPTH)
```


```{r}

# Recheck for any missing data
colSums(is.na(merged_data_clean))
```

Now we can begin the modeling process by splitting the data.
```{r}
set.seed(5034)

# Select the columns you will use
model_data <- merged_data_clean %>%
  dplyr::select(
    COUNTRY, LOCATION, LATITUDE, LONGITUDE, DAY, MONTH, YEAR,
    MIN_PERCENT_BLEACHED_CLEAN, MAX_PERCENT_BLEACHED_CLEAN, AREA,
    avg_sst, DEPTH_CLEAN, DEPTH_BIN, PERCENT_BLEACHED_CLEAN
  ) 

# Remove bad rows (like "N/A")
model_data <- model_data[model_data$MONTH != "N/A", ]

# Convert MONTH to factor *after* cleaning
model_data$MONTH <- factor(model_data$MONTH)

# Split into training and testing sets
train_index <- createDataPartition(model_data$PERCENT_BLEACHED_CLEAN, p = 0.8, list = FALSE)

train_data <- model_data[train_index, ]
test_data  <- model_data[-train_index, ]

# Check sizes
nrow(train_data)
nrow(test_data)
```

Preprocess for Modeling
```{r}

# Encode all predictors using dummyVars (fit only on train)
dummies <- dummyVars(PERCENT_BLEACHED_CLEAN ~ ., data = train_data)

# Apply to both train and test data
x_train <- predict(dummies, newdata = train_data)
x_test  <- predict(dummies, newdata = test_data)

# Convert to data frames
x_train <- as.data.frame(x_train)
x_test  <- as.data.frame(x_test)

#  Match columns (handle missing levels in test set)
missing_cols <- setdiff(names(x_train), names(x_test))
x_test[missing_cols] <- 0   # Add missing columns with zeros
x_test <- x_test[, names(x_train)]  # Ensure column order matches

# Extract response variables
y_train <- train_data$PERCENT_BLEACHED_CLEAN
y_test  <- test_data$PERCENT_BLEACHED_CLEAN

# Center and scale based on training data
pre_proc <- preProcess(x_train, method = c("center", "scale"))
x_train_scaled <- predict(pre_proc, newdata = x_train)
x_test_scaled  <- predict(pre_proc, newdata = x_test)

# Remove near-zero variance predictors
nzv <- nearZeroVar(x_train_scaled)
if (length(nzv) > 0) {
  x_train_scaled <- x_train_scaled[, -nzv]
  x_test_scaled <- x_test_scaled[, -nzv]
}
```

SVM Model
```{r}
svm_model <- train(
  x = x_train_scaled,
  y = y_train,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = 5)
)
svm_pred <- predict(svm_model, newdata = x_test_scaled)
```

Penalized Regressions
```{r}
# Ridge (Alpha = 0)
ridge_model <- train(
  x = as.matrix(x_train_scaled),
  y = y_train,
  method = "glmnet",
  trControl = trainControl(method = "cv", number = 5),
  tuneGrid = expand.grid(alpha = 0, lambda = 10^seq(-4, 2, length = 100))
)
ridge_pred <- predict(ridge_model, newdata = as.matrix(x_test_scaled))


# Lasso (Alpha = 1)
lasso_model <- train(
  x = as.matrix(x_train_scaled),
  y = y_train,
  method = "glmnet",
  trControl = trainControl(method = "cv", number = 5),
  tuneGrid = expand.grid(alpha = 1, lambda = 10^seq(-4, 2, length = 100))
)
lasso_pred <- predict(lasso_model, newdata = as.matrix(x_test_scaled))


# Elastic Net (Alpha in [0,1])
enet_model <- train(
  x = as.matrix(x_train_scaled),
  y = y_train,
  method = "glmnet",
  trControl = trainControl(method = "cv", number = 5),
  tuneLength = 10  # Tries a range of alpha & lambda
)
enet_pred <- predict(enet_model, newdata = as.matrix(x_test_scaled))
```

PLS 
```{r}
pls_model <- train(
  x = x_train_scaled,
  y = y_train,
  method = "pls",
  trControl = trainControl(method = "cv", number = 5),
  tuneLength = 20
)
pls_pred <- predict(pls_model, newdata = x_test_scaled)
```

Comparison of SVM, Penalized Regressions, and PLS
```{r}
results <- data.frame(
  Model = c("SVM", "Ridge", "Lasso", "Elastic Net", "PLS"),
  RMSE = c(
    RMSE(svm_pred, y_test),
    RMSE(ridge_pred, y_test),
    RMSE(lasso_pred, y_test),
    RMSE(enet_pred, y_test),
    RMSE(pls_pred, y_test)
  )
)

print(results)
```

Visualize the models
```{r}
# Combine all predictions into a single data frame
predictions_df <- data.frame(
  Actual = y_test,
  SVM = svm_pred,
  Ridge = ridge_pred,
  Lasso = lasso_pred,
  ElasticNet = enet_pred,
  PLS = pls_pred
)

# Pivot longer for plotting
predictions_long <- predictions_df %>%
  pivot_longer(cols = -Actual, names_to = "Model", values_to = "Predicted")

ggplot(predictions_long, aes(x = Actual, y = Predicted)) +
  geom_point(alpha = 0.6, color = "#1f77b4") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  facet_wrap(~ Model, scales = "free") +
  labs(
    title = "Predicted vs. Actual Coral Bleaching (%)",
    x = "Actual",
    y = "Predicted"
  ) +
  theme_minimal()
```

Decision Tree Model
```{r}
# Fitting the decision tree model
tree_model <- rpart(PERCENT_BLEACHED_CLEAN ~ .,
                    data = train_data,
                    method = "anova")

# Visualizing the tree
model_data_reduced <- model_data %>%
  dplyr::select(-COUNTRY, -LOCATION)

# Refit tree on reduced data
tree_model_reduced <- rpart(PERCENT_BLEACHED_CLEAN ~ ., data = model_data_reduced, method = "anova")

rpart.plot(tree_model_reduced, type = 2, extra = 101,
           fallen.leaves = TRUE, cex = 0.6,
           main = "Decision Tree for Coral Bleaching")

# Cleaner tree visualization
rpart.plot(tree_model_reduced,
           type = 4,              # labels below the split
           extra = 101,           # predicted value + % obs
           box.palette = "GnBu",  # prettier color theme
           shadow.col = "gray",   # light box shadow
           fallen.leaves = TRUE,
           branch.lty = 2,        
           branch = 0.4,          
           roundint = FALSE,      
           cex = 0.7,            
           main = "Coral Bleaching Decision Tree")



```


```{r}
summary(tree_model_reduced)
```
Based on this summary of the dataset, it can be observed that the strongest predictors of coral bleaching are historical bleaching with the minimum percent of bleached cleaned being 54% and max perecent bleached being 43% of variable importance. Other predictors such as latitdue, area, and year had minimal contribution. Features related to the ocean such as average sea surface temp and depth also had very low splitting importance, not appearing in the main branches. Using the top node split, observations with low historical bleaching minimum has an average future bleaching of 3.5% whiile high bleaching minimums has an average future bleaching of 64%.

Predicting and Evaulating using Test Dataset

```{r}
predictions <- predict(tree_model_reduced, newdata = test_data)

# Compare predictions to actuals
summary(predictions)
summary(test_data$PERCENT_BLEACHED_CLEAN)

```

Refitting decision tree without the historical bleaching

droping historical columns
```{r}
model_data_no_history <- model_data_reduced %>%
  dplyr::select(-MIN_PERCENT_BLEACHED_CLEAN, -MAX_PERCENT_BLEACHED_CLEAN)
```

refit and visualize
```{r}
tree_model_no_history <- rpart(PERCENT_BLEACHED_CLEAN ~ ., 
                               data = model_data_no_history,
                               method = "anova")

rpart.plot(tree_model_no_history,
           type = 2, extra = 101,
           box.palette = "Oranges",
           fallen.leaves = TRUE,
           cex = 0.7,
           main = "Decision Tree Without Historical Bleaching")
```


```{r}
rpart.plot(tree_model_no_history,
           type = 4,                
           extra = 101,             
           box.palette = "Oranges",  
           shadow.col = "gray",      
           cex = 0.7,               
           branch.lty = 2,          
           fallen.leaves = TRUE,
           main = "Pruned Coral Bleaching Tree (No History)")
```


```{r}
test_data$MONTH <- factor(test_data$MONTH, levels = levels(train_data$MONTH))
# Generate predictions
tree_pred_no_history <- predict(tree_model_no_history, newdata = test_data)
```


```{r}
summary(tree_model_no_history)
```
Excluding historical data from the decision tree and focusing more on environmental and contextual data, it can be seen that the first and most important split is the year 2015 as it indicates a shift in bleaching behavior post 2015. Before 2015, the bleaching trends can be observed to be much lower with shallow depths and specific months influncing the outcomes. After 2015, the mean bleaching significantly increases and seems to be influenced by month (September-December being more severe), area (more intense in the equatorial pecific and Indian Ocean), and latitdue (lower latitudes that are closer to the equator had higher bleaching).


# Random forests

Training
```{r}
rf_model <- randomForest(
  PERCENT_BLEACHED_CLEAN ~ ., 
  data = train_data,
  ntree = 500,          # Number of trees
  mtry = 3,             # Number of variables tried at each split
  importance = TRUE     # Enables variable importance metrics
)
```

Predicting with test data
```{r}
rf_pred <- predict(rf_model, newdata = test_data)

# RMSE
rf_rmse <- sqrt(mean((rf_pred - test_data$PERCENT_BLEACHED_CLEAN)^2))
print(paste("Random Forest RMSE:", round(rf_rmse, 2)))
```


```{r}
importance(rf_model)
varImpPlot(rf_model)
```
Based on the random forest model RMSE score of 2.48, this model is highly accurate with the most important predictors being latitdue (strongest driver), max_percent_bleached_clean (historical bleaching), and avg_sst (sea surface temperature).



## Linear Discriminant Analysis (LDA)

Creating Bleaching Classes
```{r}
model_data <- model_data %>%
  mutate(
    bleaching_class = case_when(
      PERCENT_BLEACHED_CLEAN < 10 ~ "low",
      PERCENT_BLEACHED_CLEAN < 50 ~ "medium",
      TRUE ~ "high"
    ) %>% as.factor()
  )
```

applying classes to training and test sets
```{r}
train_data$bleaching_class <- as.factor(case_when(
  train_data$PERCENT_BLEACHED_CLEAN < 10 ~ "low",
  train_data$PERCENT_BLEACHED_CLEAN < 50 ~ "medium",
  TRUE ~ "high"
))

test_data$bleaching_class <- as.factor(case_when(
  test_data$PERCENT_BLEACHED_CLEAN < 10 ~ "low",
  test_data$PERCENT_BLEACHED_CLEAN < 50 ~ "medium",
  TRUE ~ "high"
))
```

train LDA
```{r}
lda_model <- lda(bleaching_class ~ LATITUDE + LONGITUDE + YEAR + MONTH + avg_sst + DEPTH_CLEAN + AREA,
                 data = train_data)
```

predict using test set
```{r}
lda_pred <- predict(lda_model, newdata = test_data)
```

performance
```{r}
#confusion matrix
table(Predicted = lda_pred$class, Actual = test_data$bleaching_class)

# Accuracy
mean(lda_pred$class == test_data$bleaching_class)
```
This accuracy shows that the LDA model only correctly classifies 71.93% of coral bleaching classes with  the low class being the most frequent classification. This model only performs moderately well with limitations on performance due to class overlap.

Linear Regression
```{r}
# LINEAR REGRESSION
lm_model <- lm(PERCENT_BLEACHED_CLEAN ~ avg_sst + DEPTH_CLEAN + YEAR + MONTH, data = train_data)

# Summary of model
summary(lm_model)

# Predict on test data
lm_predictions <- predict(lm_model, newdata = test_data)

# Evaluate RMSE
lm_rmse <- sqrt(mean((lm_predictions - test_data$PERCENT_BLEACHED_CLEAN)^2, na.rm = TRUE))
cat("Linear Regression RMSE:", lm_rmse, "\n")

# Plot: Predicted vs Actual
ggplot(data = NULL, aes(x = test_data$PERCENT_BLEACHED_CLEAN, y = lm_predictions)) +
  geom_point(alpha = 0.4, color = "blue") +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(title = "Linear Regression: Predicted vs. Actual",
       x = "Actual % Bleached", y = "Predicted % Bleached") +
  theme_minimal()

```

LOGISTIC REGRESSION
```{r}
# LOGISTIC REGRESSION

# Create binary outcome: High Bleaching if > 50%
train_data$Bleached_High <- ifelse(train_data$PERCENT_BLEACHED_CLEAN > 50, 1, 0)
test_data$Bleached_High  <- ifelse(test_data$PERCENT_BLEACHED_CLEAN > 50, 1, 0)

# LOGISTIC REGRESSION
log_model <- glm(Bleached_High ~ avg_sst + DEPTH_CLEAN + YEAR + MONTH, 
                 data = train_data, family = "binomial")

# Summary
summary(log_model)

# Predict probabilities
log_probs <- predict(log_model, newdata = test_data, type = "response")
log_preds <- ifelse(log_probs > 0.5, 1, 0)

# Confusion matrix
library(caret)
confusionMatrix(factor(log_preds), factor(test_data$Bleached_High))

# Plot: Confusion Matrix
log_cm <- confusionMatrix(factor(log_preds), factor(test_data$Bleached_High))
fourfoldplot(log_cm$table,
             color = c("#E41A1C", "#377EB8"),
             main = "Logistic Regression: Confusion Matrix")

# ROC and AUC
library(pROC)
log_roc <- roc(test_data$Bleached_High, log_probs)
plot(log_roc, col = "blue", main = "ROC Curve - Logistic Regression")
auc(log_roc)
```

 k-NN with k Optimization
```{r}
# Normalize helper
normalize <- function(x) {
  return((x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))
}

# Ensure MONTH is numeric
train_data$MONTH <- as.numeric(train_data$MONTH)
test_data$MONTH  <- as.numeric(test_data$MONTH)

# Create binary outcome
train_data$Bleached_High_Factor <- factor(
  ifelse(train_data$PERCENT_BLEACHED_CLEAN >= 20, "Yes", "No"),
  levels = c("No", "Yes")
)

# k-NN train set: select and normalize
knn_train_set <- train_data %>%
  dplyr::select(avg_sst, DEPTH_CLEAN, YEAR, MONTH, Bleached_High_Factor) %>%
  dplyr::mutate(across(c(avg_sst, DEPTH_CLEAN, YEAR, MONTH), normalize))

# Rename for caret compatibility
colnames(knn_train_set)[colnames(knn_train_set) == "Bleached_High_Factor"] <- "Bleached_High"

# Prepare test set
knn_test_set <- test_data %>%
  dplyr::select(avg_sst, DEPTH_CLEAN, YEAR, MONTH) %>%
  dplyr::mutate(across(everything(), normalize))

# Drop rows with NA
knn_train_set <- knn_train_set %>% tidyr::drop_na()

control <- trainControl(method = "cv", number = 10, classProbs = TRUE)
grid <- expand.grid(k = seq(1, 21, 2))  # test odd k values

set.seed(5034)
knn_cv_model <- train(
  Bleached_High ~ .,
  data = knn_train_set,
  method = "knn",
  trControl = control,
  tuneGrid = grid
)

# View performance
plot(knn_cv_model)
print(knn_cv_model$bestTune)
```

Final k-NN Evaluation (Confusion Matrix + ROC/AUC)
```{r}
# Prepare inputs
test_input <- knn_test_set %>% drop_na()

# Match cleaned labels for test set
test_labels <- test_data %>%
  filter(!is.na(avg_sst) & !is.na(DEPTH_CLEAN) & !is.na(YEAR) & !is.na(MONTH)) %>%
  mutate(Bleached_High_Factor = factor(
    ifelse(PERCENT_BLEACHED_CLEAN >= 20, "Yes", "No"),
    levels = c("No", "Yes"))
  ) %>%
  pull(Bleached_High_Factor)

# Predict
best_k <- knn_cv_model$bestTune$k
train_input <- knn_train_set %>% dplyr::select(-Bleached_High)
train_target <- knn_train_set$Bleached_High

knn_preds <- class::knn(
  train = train_input,
  test = test_input,
  cl = train_target,
  k = best_k,
  prob = TRUE
)

# Confusion matrix
caret::confusionMatrix(knn_preds, test_labels)

# ROC and AUC
library(pROC)

knn_prob_values <- ifelse(knn_preds == "Yes", 
                          attr(knn_preds, "prob"), 
                          1 - attr(knn_preds, "prob"))

knn_roc <- roc(response = test_labels, predictor = knn_prob_values)

plot(knn_roc, col = "darkgreen", main = paste("ROC Curve - k-NN (k =", best_k, ")"))
auc(knn_roc)

```


```{r final_model_comparison}
# MODEL COMPARISON SUMMARY

library(knitr)
library(pROC)

# Linear Regression: RMSE
lm_rmse <- sqrt(mean((lm_predictions - test_data$PERCENT_BLEACHED_CLEAN)^2, na.rm = TRUE))
# Logistic Regression: Accuracy and AUC
log_accuracy <- mean(log_preds == test_data$Bleached_High, na.rm = TRUE)
log_roc <- roc(test_data$Bleached_High, log_probs)
log_auc <- auc(log_roc)
# k-NN: Accuracy and AUC
knn_accuracy <- mean(knn_preds == test_labels)
knn_auc <- auc(knn_roc)

# RMSE values for regression models
svm_rmse <- RMSE(svm_pred, y_test)
ridge_rmse <- RMSE(ridge_pred, y_test)
lasso_rmse <- RMSE(lasso_pred, y_test)
enet_rmse <- RMSE(enet_pred, y_test)
pls_rmse <- RMSE(pls_pred, y_test)
rf_rmse <- sqrt(mean((rf_pred - test_data$PERCENT_BLEACHED_CLEAN)^2))
tree_rmse <- sqrt(mean((tree_pred_no_history - test_data$PERCENT_BLEACHED_CLEAN)^2, na.rm = TRUE))


lm_rmse <- sqrt(mean((lm_predictions - test_data$PERCENT_BLEACHED_CLEAN)^2, na.rm = TRUE))
log_accuracy <- mean(log_preds == test_data$Bleached_High, na.rm = TRUE)
log_roc <- roc(test_data$Bleached_High, log_probs)
log_auc <- auc(log_roc)

knn_accuracy <- mean(knn_preds == test_labels)
knn_auc <- auc(knn_roc)

# LDA Accuracy
lda_accuracy <- mean(lda_pred$class == test_data$bleaching_class)

# Summary Table 

model_summary <- data.frame(
  Model = c(
    "Linear Regression", "Random Forest", "Decision Tree",
    "SVM", "Ridge", "Lasso", "Elastic Net", "PLS",
    "Logistic Regression", "k-Nearest Neighbors", "LDA"
  ),
  Metric = c(
    rep("RMSE", 8),
    rep("Accuracy", 3)
  ),
  Value = c(
    lm_rmse, rf_rmse, tree_rmse,
    svm_rmse, ridge_rmse, lasso_rmse, enet_rmse, pls_rmse,
    log_accuracy, knn_accuracy, lda_accuracy
  ),
  AUC = c(
    rep(NA, 8),
    log_auc, knn_auc, NA
  )
)

# Output the table
kable(model_summary, digits = 3, caption = "Model Performance Summary")
```


R Shiny App
```{r Shiny}
# R SHINY
# Get MONTH
MONTH = input$month
historical_points <- merged_data_clean %>%
  dplyr::filter(!is.na(LATITUDE), !is.na(LONGITUDE)) %>%
  dplyr::select(LATITUDE, LONGITUDE, PERCENT_BLEACHED_CLEAN) %>%
  dplyr::distinct()

# UI
ui <- fluidPage(
  titlePanel("Coral Bleaching Predictor with Ocean Map"),
  sidebarLayout(
    sidebarPanel(
      numericInput("sst", "Avg SST (°C):", value = 28, min = 20, max = 35, step = 0.1),
      numericInput("depth", "Depth (m):", value = 10, min = 0, max = 100),
      numericInput("year", "Year:", value = 2025, min = 1980, max = 2035),
      numericInput("month", "Month (1–12):", value = 6, min = 1, max = 12),
      numericInput("lat", "Latitude (Ocean Only)", value = 0, min = -60, max = 30),
      numericInput("lon", "Longitude (Ocean Only)", value = 0, min = -180, max = 180),
      actionButton("predict_btn", "Predict Bleaching Risk")
    ),
    mainPanel(
      h3("Prediction Result"),
      verbatimTextOutput("prediction_output"),
      h3("Location and Historical Sites"),
      leafletOutput("map", height = 500)
    )
  )
)

# Server
server <- function(input, output) {
  observeEvent(input$predict_btn, {
    new_data <- data.frame(
      avg_sst = input$sst,
      DEPTH_CLEAN = input$depth,
      YEAR = input$year,
      MONTH = input$month
    )
    
    prob <- predict(log_model, newdata = new_data, type = "response")
    classification <- ifelse(prob > 0.5, "High Bleaching Risk", "Low Bleaching Risk")
    
    output$prediction_output <- renderText({
      paste0("Predicted probability of high bleaching: ", round(prob * 100, 1), "%\n",
             "Classification: ", classification)
    })
    
    # Marker color
    marker_color <- ifelse(prob > 0.5, "red", "green")
    
    # Render Leaflet map
    output$map <- renderLeaflet({
      leaflet() %>%
        addProviderTiles(providers$Esri.OceanBasemap) %>%
        setView(lng = input$lon, lat = input$lat, zoom = 3) %>%
        
        # Add historical bleaching points
        addCircles(
          data = historical_points,
          lng = ~LONGITUDE, lat = ~LATITUDE,
          color = "blue", radius = 30000, opacity = 0.3,
          label = ~paste("Historical Bleaching:", round(PERCENT_BLEACHED_CLEAN, 1), "%")
        ) %>%
        
        # Add prediction marker
        addCircleMarkers(
          lng = input$lon, lat = input$lat,
          color = marker_color,
          radius = 8, fillOpacity = 0.9,
          label = paste0("Prediction: ", classification, 
                         " (", round(prob * 100, 1), "%)")
        )
    })
  })
}

shinyApp(ui = ui, server = server)
```


```{r}
library(leaflet)

```


